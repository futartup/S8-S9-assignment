{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "resnet_gradcam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futartup/S8-assignment/blob/master/resnet_gradcam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCcDQolpuaPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Function\n",
        "from torchvision import models\n",
        "from torchvision import utils\n",
        "import cv2\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96DzHfvuuaP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResnetGradCam():\n",
        "  def __init__(self):\n",
        "    # get the pretrained resnet18 model\n",
        "    self.resnet18 = torchvision.models.resnet18(pretrained=True)\n",
        "    \n",
        "    # dissect the network to access its last convolutional layer\n",
        "    self.last_conv_layer = self.resnet18.layer4\n",
        "    \n",
        "    # add the average pool \n",
        "    self.global_avg_pool = nn.AvgPool2d(kernel_size=3, stride=1)\n",
        "\n",
        "    # get the classifier of resnet18\n",
        "    self.classifier = self.resnet18.fc\n",
        "\n",
        "    # placeholder for gradients\n",
        "    self.gradients = None\n",
        "\n",
        "  def activations_hook(self, grad):\n",
        "    self.gradients = grad\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.last_conv_layer(x)\n",
        "\n",
        "    # register the hook\n",
        "    h = x.register_hook(self.activations_hook)\n",
        "\n",
        "    x = self.global_avg_pool(x)\n",
        "    x = x.view((1, 1000))\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "  def get_activations_gradient(self):\n",
        "    return self.gradients\n",
        "\n",
        "  def get_activations(self, x):\n",
        "    return self.last_conv_layer(x)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYQblITcFtQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_gradcam_cifar10(train_loader):\n",
        "  resnet_obj = ResnetGradCam()\n",
        "  resnet_obj.eval()\n",
        "  img, _ = next(iter(train_loader))\n",
        "\n",
        "  pred = resnet_obj(img).argmax(dim=1)\n",
        "\n",
        "  pred[:, 386].backward()\n",
        "\n",
        "  # pull the gradients out of the model\n",
        "  gradients = resnet_obj.get_activations_gradient()\n",
        "\n",
        "  # pool the gradients across the channels\n",
        "  pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
        "\n",
        "  # get the activations of the last convolutional layer\n",
        "  activations = resnet_obj.get_activations(img).detach()\n",
        "\n",
        "  # weight the channels by corresponding gradients\n",
        "  for i in range(512):\n",
        "      activations[:, i, :, :] *= pooled_gradients[i]\n",
        "      \n",
        "  # average the channels of the activations\n",
        "  heatmap = torch.mean(activations, dim=1).squeeze()\n",
        "\n",
        "  # relu on top of the heatmap\n",
        "  heatmap = np.maximum(heatmap, 0)\n",
        "\n",
        "  # normalize the heatmap\n",
        "  heatmap /= torch.max(heatmap)\n",
        "\n",
        "  # draw the heatmap\n",
        "  plt.matshow(heatmap.squeeze())\n",
        "\n",
        "  \n",
        "  img = cv2.imread(img)\n",
        "  heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "  heatmap = np.uint8(255 * heatmap)\n",
        "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "  superimposed_img = heatmap * 0.4 + img\n",
        "  cv2.imwrite('./map.jpg', superimposed_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfNDCgcUhVAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class GradCAM:\n",
        "    \"\"\"Calculate GradCAM salinecy map.\n",
        "    Args:\n",
        "        input: Input image with shape of (1, 3, H, W)\n",
        "        class_idx: Class index for calculating GradCAM.\n",
        "            If not specified, the class index that makes the highest model prediction score will be used.\n",
        "    Returns:\n",
        "        mask: Saliency map of the same spatial dimension with input\n",
        "        logit: Model output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, layer_name):\n",
        "        self.model = model\n",
        "        self.layer_name = layer_name\n",
        "        self._target_layer()\n",
        "\n",
        "        self.gradients = dict()\n",
        "        self.activations = dict()\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            self.gradients['value'] = grad_output[0]\n",
        "\n",
        "        def forward_hook(module, input, output):\n",
        "            self.activations['value'] = output\n",
        "\n",
        "        self.target_layer.register_forward_hook(forward_hook)\n",
        "        self.target_layer.register_backward_hook(backward_hook)\n",
        "    \n",
        "    def _target_layer(self):\n",
        "        layer_num = int(self.layer_name.lstrip('layer'))\n",
        "        if layer_num == 1:\n",
        "            self.target_layer = self.model.layer1\n",
        "        elif layer_num == 2:\n",
        "            self.target_layer = self.model.layer2\n",
        "        elif layer_num == 3:\n",
        "            self.target_layer = self.model.layer3\n",
        "        elif layer_num == 4:\n",
        "            self.target_layer = self.model.layer4\n",
        "\n",
        "    def saliency_map_size(self, *input_size):\n",
        "        device = next(self.model.parameters()).device\n",
        "        self.model(torch.zeros(1, 3, *input_size, device=device))\n",
        "        return self.activations['value'].shape[2:]\n",
        "\n",
        "    def forward(self, input, class_idx=None, retain_graph=False):\n",
        "        b, c, h, w = input.size()\n",
        "\n",
        "        logit = self.model(input)\n",
        "        if class_idx is None:\n",
        "            score = logit[:, logit.max(1)[-1]].squeeze()\n",
        "        else:\n",
        "            score = logit[:, class_idx].squeeze()\n",
        "\n",
        "        self.model.zero_grad()\n",
        "        score.backward(retain_graph=retain_graph)\n",
        "        gradients = self.gradients['value']\n",
        "        activations = self.activations['value']\n",
        "        b, k, u, v = gradients.size()\n",
        "\n",
        "        alpha = gradients.view(b, k, -1).mean(2)\n",
        "        # alpha = F.relu(gradients.view(b, k, -1)).mean(2)\n",
        "        weights = alpha.view(b, k, 1, 1)\n",
        "\n",
        "        saliency_map = (weights*activations).sum(1, keepdim=True)\n",
        "        saliency_map = F.relu(saliency_map)\n",
        "        saliency_map = F.upsample(saliency_map, size=(h, w), mode='bilinear', align_corners=False)\n",
        "        saliency_map_min, saliency_map_max = saliency_map.min(), saliency_map.max()\n",
        "        saliency_map = (saliency_map - saliency_map_min).div(saliency_map_max - saliency_map_min).data\n",
        "\n",
        "        return saliency_map, logit\n",
        "\n",
        "    def __call__(self, input, class_idx=None, retain_graph=False):\n",
        "        return self.forward(input, class_idx, retain_graph)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}