{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "resnet_gradcam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futartup/S8-assignment/blob/master/resnet_gradcam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO1v7D8nQKfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import os, sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KspYVHCwQLIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResnetGradCam(nn.Module):\n",
        "  def __init__(self, model):\n",
        "    super(ResnetGradCam, self).__init__()\n",
        "\n",
        "    # get the pretrained resnet18 model\n",
        "    self.resnet18 = model\n",
        "    \n",
        "    # dissect the network to access its last convolutional layer\n",
        "    self.features_conv = nn.Sequential(self.resnet18.conv1,\n",
        "                                           self.resnet18.bn1,\n",
        "                                           self.resnet18.layer1,\n",
        "                                           self.resnet18.layer2,\n",
        "                                           self.resnet18.layer3,\n",
        "                                           self.resnet18.layer4\n",
        "                                           )  # list(self.resx.children())[:-5]\n",
        "\n",
        "    self.linear = self.resnet18.linear\n",
        "\n",
        "    # placeholder for the gradients\n",
        "    self.gradients = None\n",
        "\n",
        "  def activations_hook(self, grad):\n",
        "    self.gradients = grad\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features_conv(x)\n",
        "\n",
        "    # register the hook\n",
        "    h = x.register_hook(self.activations_hook)\n",
        "\n",
        "    x = F.avg_pool2d(x, 4)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.linear(x)\n",
        "    return x\n",
        "\n",
        "  def get_activations_gradient(self):\n",
        "    return self.gradients\n",
        "\n",
        "  def get_activations(self, x):\n",
        "    return self.features_conv(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UbKOtPpQZlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getheatmap(pred, class_pred, netx, img):\n",
        "    # get the gradient of the output with respect to the parameters of the model\n",
        "    pred[:, class_pred].backward()\n",
        "    # pull the gradients out of the model\n",
        "    gradients = netx.get_activations_gradient()\n",
        "\n",
        "    # pool the gradients across the channels\n",
        "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
        "\n",
        "    # get the activations of the last convolutional layer\n",
        "    activations = netx.get_activations(img.cuda()).detach()\n",
        "\n",
        "    # weight the channels by corresponding gradients\n",
        "    for i in range(512):\n",
        "        activations[:, i, :, :] *= pooled_gradients[i]\n",
        "\n",
        "    # average the channels of the activations\n",
        "    heatmap = torch.mean(activations, dim=1).squeeze()\n",
        "\n",
        "    # relu on top of the heatmap\n",
        "    # expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
        "    heatmap = np.maximum(heatmap.cpu(), 0)\n",
        "\n",
        "    # normalize the heatmap\n",
        "    heatmap /= torch.max(heatmap)\n",
        "    # heatmap = None\n",
        "    return heatmap\n",
        "\n",
        "\n",
        "def imshow(img, ax):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.cpu().numpy()\n",
        "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "def superposeimage(heatmap, img):\n",
        "    heat1 = np.array(heatmap)\n",
        "    heatmap1 = cv2.resize(heat1, (img.shape[1], img.shape[0]))\n",
        "    heatmap1 = np.uint8(255 * heatmap1)\n",
        "    heatmap1 = cv2.applyColorMap(heatmap1, cv2.COLORMAP_JET)\n",
        "    superimposed_img = heatmap1 * 0.4 + img\n",
        "    cv2.imwrite('./map.jpg', superimposed_img)\n",
        "\n",
        "\n",
        "def gradcamof(net, imgs, classes):\n",
        "    netx = ResnetGradCam(net)\n",
        "    netx.eval()\n",
        "\n",
        "    for img in imgs:\n",
        "        fig, axes = plt.subplots(nrows=1, ncols=3)\n",
        "        # get the most likely prediction of the model\n",
        "        pred = netx(img.cuda())\n",
        "        from torchvision.utils import save_image\n",
        "        imx = img[0]\n",
        "        save_image(imx, 'img1.png')\n",
        "        class_pred = int(np.array(pred.cpu().argmax(dim=1)))\n",
        "        imshow(torchvision.utils.make_grid(img), axes[0])\n",
        "        print(classes[class_pred])\n",
        "        # axes.set_title(str(classes[class_pred]))\n",
        "\n",
        "        # draw the heatmap\n",
        "        heatmap = getheatmap(pred, class_pred, netx, img)\n",
        "        axes[1].matshow(heatmap.squeeze())\n",
        "\n",
        "        imx = cv2.imread(\"./img1.png\")\n",
        "        imx = cv2.cvtColor(imx, cv2.COLOR_BGR2RGB)\n",
        "        # plt.imshow(imx, cmap='gray', interpolation='bicubic')\n",
        "        superposeimage(heatmap, imx)\n",
        "\n",
        "        imx = cv2.imread('./map.jpg')\n",
        "        imx = cv2.cvtColor(imx, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # scale_percent = 220  # percent of original size\n",
        "        # width = int(imx.shape[1] * scale_percent / 100)\n",
        "        # height = int(imx.shape[0] * scale_percent / 100)\n",
        "        # dim = (width, height)\n",
        "        # # resize image\n",
        "        # imx = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
        "        axes[2].imshow(imx, cmap='gray', interpolation='bicubic')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}