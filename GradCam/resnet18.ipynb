{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "resnet18.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futartup/S8-assignment/blob/master/GradCam/resnet18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jW9mYxAYDnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "try:\n",
        "  import ipynb\n",
        "except:\n",
        "  !pip install ipynb --upgrade\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import os, sys\n",
        "import cv2\n",
        "if '/content/drive/My Drive/Colab Notebooks/S8' not in sys.path:\n",
        "  sys.path.append('/content/drive/My Drive/Colab Notebooks/S8')\n",
        "from ipynb.fs.full.transform_train_test_loader import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFoVuBVWba56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class ResnetGradCam(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ResnetGradCam, self).__init__()\n",
        "\n",
        "    # get the pretrained resnet18 model\n",
        "    self.resnet18 = torchvision.models.resnet18(pretrained=True)\n",
        "    \n",
        "    # dissect the network to access its last convolutional layer\n",
        "    self.last_conv_layer = self.resnet18.layer4\n",
        "    \n",
        "    # add the average pool \n",
        "    self.global_avg_pool = nn.AvgPool2d(kernel_size=3, stride=1)\n",
        "\n",
        "    # get the classifier of resnet18\n",
        "    self.classifier = self.resnet18.fc\n",
        "\n",
        "    # placeholder for gradients\n",
        "    self.gradients = None\n",
        "\n",
        "  def activations_hook(self, grad):\n",
        "    self.gradients = grad\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.last_conv_layer(x)\n",
        "\n",
        "    # register the hook\n",
        "    h = x.register_hook(self.activations_hook)\n",
        "\n",
        "    x = self.global_avg_pool(x)\n",
        "    x = x.view((1, 1000))\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "  def get_activations_gradient(self):\n",
        "    return self.gradients\n",
        "\n",
        "  def get_activations(self, x):\n",
        "    return self.last_conv_layer(x)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwijKnZVL9Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_gradcam_cifar10(train_loader, image):\n",
        "  train_loader = get_train_loader()\n",
        "  resnet_obj = ResnetGradCam()\n",
        "  resnet_obj.eval()\n",
        "  img, _ = next(iter(train_loader))\n",
        "\n",
        "  pred = resnet_obj(img).argmax(dim=1)\n",
        "\n",
        "  pred[:, 386].backward()\n",
        "\n",
        "  # pull the gradients out of the model\n",
        "  gradients = resnet_obj.get_activations_gradient()\n",
        "\n",
        "  # pool the gradients across the channels\n",
        "  pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
        "\n",
        "  # get the activations of the last convolutional layer\n",
        "  activations = resnet_obj.get_activations(img).detach()\n",
        "\n",
        "  # weight the channels by corresponding gradients\n",
        "  for i in range(512):\n",
        "      activations[:, i, :, :] *= pooled_gradients[i]\n",
        "      \n",
        "  # average the channels of the activations\n",
        "  heatmap = torch.mean(activations, dim=1).squeeze()\n",
        "\n",
        "  # relu on top of the heatmap\n",
        "  # expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
        "  heatmap = np.maximum(heatmap, 0)\n",
        "\n",
        "  # normalize the heatmap\n",
        "  heatmap /= torch.max(heatmap)\n",
        "\n",
        "  # draw the heatmap\n",
        "  plt.matshow(heatmap.squeeze())\n",
        "\n",
        "  \n",
        "  img = cv2.imread(img)\n",
        "  heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "  heatmap = np.uint8(255 * heatmap)\n",
        "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "  superimposed_img = heatmap * 0.4 + img\n",
        "  cv2.imwrite('./map.jpg', superimposed_img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}